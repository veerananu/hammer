package sender

import (
	"bytes"
	"context"
	"fmt"
	"io"
	"log"
	"math"
	"net/http"
	"os"
	"sync"
	"time"

	"my-lambda-project/internal/config"
	"my-lambda-project/internal/metrics"

	jsoniter "github.com/json-iterator/go"
)

var jsonLib = jsoniter.ConfigCompatibleWithStandardLibrary

// client is the HTTP client used to send requests.
var client = &http.Client{
	Timeout: 10 * time.Second,
	Transport: &http.Transport{
		MaxIdleConns:        100,
		MaxIdleConnsPerHost: 30,
	},
}

// Sender collects ResourceMetrics from resultChan into batches and sends them via batchChan.
// It returns a batchChan and a done channel that is closed when all batches have been flushed.
func Sender(ctx context.Context, resultChan <-chan metrics.ResourceMetrics, cfg *config.Config, batchSize int, flushInterval time.Duration) (<-chan []metrics.ResourceMetrics, <-chan struct{}) {
	batchChan := make(chan []metrics.ResourceMetrics, cfg.BatchChanSize)
	done := make(chan struct{})

	go func() {
		batch := make([]metrics.ResourceMetrics, 0, batchSize)
		timer := time.NewTimer(flushInterval)
		defer func() {
			if len(batch) > 0 {
				batchChan <- batch
			}
			timer.Stop()
			close(batchChan)
			close(done)
		}()

		for {
			select {
			case rm, ok := <-resultChan:
				if !ok {
					return
				}
				// Log the metric as JSON if PrintJSON is enabled.
				if cfg.PrintJSON {
					// Wrap the single metric in ExportMetricsServiceRequest for correct top-level structure.
					wrapped := metrics.ExportMetricsServiceRequest{
						ResourceMetrics: []metrics.ResourceMetrics{rm},
					}
					jsonMetric, err := jsonLib.MarshalIndent(wrapped, "", "  ")
					if err != nil {
						log.Printf("Error marshaling metric: %v", err)
					} else {
						log.Printf("Sender received metric:\n%s", string(jsonMetric))
					}
				} else {
					log.Printf("Sender received metric: %v", rm)
				}
				batch = append(batch, rm)
				if len(batch) >= batchSize {
					batchChan <- batch
					batch = make([]metrics.ResourceMetrics, 0, batchSize)
					if !timer.Stop() {
						<-timer.C
					}
					timer.Reset(flushInterval)
				}
			case <-timer.C:
				if len(batch) > 0 {
					batchChan <- batch
					batch = make([]metrics.ResourceMetrics, 0, batchSize)
				}
				timer.Reset(flushInterval)
			case <-ctx.Done():
				return
			}
		}
	}()

	return batchChan, done
}

// StartWorkers launches worker goroutines that process batches from batchChan.
// It returns a workersDone channel that closes when all workers finish.
func StartWorkers(ctx context.Context, batchChan <-chan []metrics.ResourceMetrics, cfg *config.Config, numWorkers int) chan struct{} {
	workersDone := make(chan struct{})
	var wg sync.WaitGroup

	for i := 0; i < numWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			worker(ctx, batchChan, cfg)
		}()
	}

	go func() {
		wg.Wait()
		close(workersDone)
	}()

	return workersDone
}

// worker processes batches from batchChan and sends them using sendBatch.
func worker(ctx context.Context, batchChan <-chan []metrics.ResourceMetrics, cfg *config.Config) {
	for batch := range batchChan {
		log.Printf("Worker: received batch of length %d", len(batch))
		sendBatch(ctx, batch, cfg)
	}
}

// sendBatch sends a batch of ResourceMetrics to the OTEL endpoint with retry logic.
func sendBatch(ctx context.Context, batch []metrics.ResourceMetrics, cfg *config.Config) {
	// Wrap the batch in the top-level "resourceMetrics" object.
	requestData := metrics.ExportMetricsServiceRequest{
		ResourceMetrics: batch,
	}

	// Marshal the complete payload as pretty JSON.
	fullPayload, err := jsonLib.MarshalIndent(requestData, "", "  ")
	if err != nil {
		log.Printf("Error marshaling full OTEL payload: %v", err)
	} else {
		// Log the complete payload.
		log.Printf("FULL OTEL PAYLOAD:\n%s", string(fullPayload))
		fmt.Println("FULL OTEL PAYLOAD:")
		fmt.Println(string(fullPayload))
	}

	// Marshal the compact payload for sending.
	jsonData, err := jsonLib.Marshal(requestData)
	if err != nil {
		log.Printf("Error marshaling JSON for sending: %v", err)
		return
	}

	// If LOCAL_TEST is enabled, print the full payload and exit without sending.
	if os.Getenv("LOCAL_TEST") == "true" {
		log.Printf("LOCAL_TEST mode: Would send full payload:\n%s", string(fullPayload))
		return
	}

	// Sending with retry logic.
	for attempt := 0; attempt <= cfg.MaxRetries; attempt++ {
		select {
		case <-ctx.Done():
			log.Printf("Send cancelled: %v", ctx.Err())
			return
		default:
		}

		req, err := http.NewRequestWithContext(ctx, "POST", cfg.OTELEndpoint, bytes.NewBuffer(jsonData))
		if err != nil {
			log.Printf("Error creating request: %v", err)
			return
		}
		req.Header.Set("Content-Type", "application/json")

		log.Printf("Attempt %d to send full payload", attempt+1)
		resp, err := client.Do(req)
		if err == nil && resp.StatusCode == http.StatusOK {
			log.Printf("Successfully sent full payload with %d ResourceMetrics", len(batch))
			if resp != nil {
				resp.Body.Close()
			}
			return
		}

		if resp != nil {
			body, _ := io.ReadAll(resp.Body)
			resp.Body.Close()
			log.Printf("Attempt %d: received status %d. Response: %s", attempt+1, resp.StatusCode, string(body))
		} else {
			log.Printf("Attempt %d failed: %v", attempt+1, err)
		}

		if attempt < cfg.MaxRetries {
			backoff := cfg.Backoff * time.Duration(math.Pow(cfg.BackoffMult, float64(attempt)))
			log.Printf("Retrying in %v...", backoff)
			select {
			case <-time.After(backoff):
			case <-ctx.Done():
				log.Printf("Send cancelled during backoff: %v", ctx.Err())
				return
			}
		} else {
			log.Printf("Failed to send payload after %d attempts", cfg.MaxRetries+1)
		}
	}
}


package main

import (
	"bufio"
	"bytes"
	"context"
	"io"
	"log"
	"my-lambda-project/internal/config"
	"my-lambda-project/internal/metrics"
	"my-lambda-project/internal/s3" // internal package
	"my-lambda-project/internal/sender"
	"os"
	"time"

	"github.com/aws/aws-lambda-go/events"
	"github.com/aws/aws-lambda-go/lambda"
	jsoniter "github.com/json-iterator/go"

	// AWS SDK s3 package
	awsS3 "github.com/aws/aws-sdk-go/service/s3" // AWS SDK's S3 package
)

var jsonLib = jsoniter.ConfigCompatibleWithStandardLibrary
var s3FailureCount int

func handler(ctx context.Context, s3Event events.S3Event) error {
	cfg := config.Load()

	for _, record := range s3Event.Records {
		var inputData []byte
		var err error
		var bucket, key string

		if os.Getenv("LOCAL_TEST") == "true" {
			localFilePath := "test/test_metrics.json"
			inputData, err = os.ReadFile(localFilePath)
			if err != nil {
				log.Printf("Failed to read local file %s: %v", localFilePath, err)
				continue
			}
		} else {
			s3Client, err := s3.GetClient()
			if err != nil {
				log.Printf("Failed to initialize S3 client: %v", err)
				return err
			}
			bucket = record.S3.Bucket.Name
			key = record.S3.Object.Key
			resp, err := s3Client.GetObjectWithContext(ctx, &awsS3.GetObjectInput{
				Bucket: &bucket,
				Key:    &key,
			})
			if err != nil {
				log.Printf("Failed to get object %s from bucket %s: %v", key, bucket, err)
				s3FailureCount++
				continue
			}
			defer resp.Body.Close()
			inputData, err = io.ReadAll(resp.Body)
			if err != nil {
				log.Printf("Failed to read object %s: %v", key, err)
				s3FailureCount++
				continue
			}
		}

		// --- JSON Parsing ---
		// Support both JSON array and newline-delimited JSON objects.
		var inputs []metrics.InputMetric
		trimmedData := bytes.TrimSpace(inputData)
		if len(trimmedData) > 0 && trimmedData[0] == '[' {
			// Input is a JSON array.
			if err := jsonLib.Unmarshal(inputData, &inputs); err != nil {
				log.Printf("Error parsing JSON array: %v", err)
				continue
			}
		} else {
			// Input is newline-delimited JSON (NDJSON).
			scanner := bufio.NewScanner(bytes.NewReader(inputData))
			for scanner.Scan() {
				line := scanner.Bytes()
				if len(bytes.TrimSpace(line)) == 0 {
					continue
				}
				var metric metrics.InputMetric
				if err := jsonLib.Unmarshal(line, &metric); err != nil {
					log.Printf("Error parsing JSON object: %v", err)
					continue
				}
				inputs = append(inputs, metric)
			}
			if err := scanner.Err(); err != nil {
				log.Printf("Error reading metrics: %v", err)
				continue
			}
		}

		resultChan := make(chan metrics.ResourceMetrics, cfg.ResultChanSize)
		flushInterval := 10 * time.Second

		batchChan, done := sender.Sender(ctx, resultChan, cfg, cfg.BatchSize, flushInterval)
		workersDone := sender.StartWorkers(ctx, batchChan, cfg, cfg.NumWorkers)

		startTime := time.Now()
		metrics.ConvertToOTEL(ctx, inputs, resultChan)
		log.Printf("Processed %d metrics. Time taken: %v. Failed S3 records: %d", len(inputs), time.Since(startTime), s3FailureCount)

		<-done        // Wait for all batches to be sent to batchChan
		<-workersDone // Wait for all workers to finish sending batches

		if os.Getenv("LOCAL_TEST") == "true" {
			log.Printf("Local test mode: would update S3 object (bucket: %s, key: %s) as processed", bucket, key)
		} else {
			s3Client, err := s3.GetClient()
			if err != nil {
				log.Printf("Failed to reinitialize S3 client for update: %v", err)
			} else {
				err = s3.UpdateObjectStatus(s3Client, bucket, key)
				if err != nil {
					log.Printf("Error updating object status for %s/%s: %v", bucket, key, err)
				} else {
					log.Printf("Successfully updated object status for %s/%s", bucket, key)
				}
			}
		}
	}
	return nil
}

func localTest() {
	eventData, err := os.ReadFile("test/s3_event.json")
	if err != nil {
		log.Fatalf("Failed to read event file: %v", err)
	}
	log.Printf("S3 event file content:\n%s", eventData)

	var s3Event events.S3Event
	if err := jsonLib.Unmarshal(eventData, &s3Event); err != nil {
		log.Fatalf("Failed to unmarshal event: %v", err)
	}

	metricsData, err := os.ReadFile("test/test_metrics.json")
	if err != nil {
		log.Fatalf("Failed to read metrics file: %v", err)
	}
	log.Printf("Metrics file content:\n%s", metricsData)

	os.Setenv("LOCAL_TEST", "true")
	if len(os.Args) > 2 && os.Args[2] == "printjson" {
		os.Setenv("PRINT_JSON", "true")
		log.Printf("PRINT_JSON set to %s", os.Getenv("PRINT_JSON"))
	}

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cancel()

	if err := handler(ctx, s3Event); err != nil {
		log.Printf("Handler error: %v", err)
	} else {
		log.Println("Handler executed successfully")
	}
}

func main() {
	if len(os.Args) > 1 && os.Args[1] == "local" {
		localTest()
	} else {
		lambda.Start(handler)
	}
}
